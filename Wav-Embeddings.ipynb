{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2de082",
   "metadata": {},
   "source": [
    "# Audio Embeddings Generator (OpenL3, PANNs) + Song Recommendations\n",
    "\n",
    "This notebook demonstrates how to generate audio embeddings using two different state-of-the-art models:\n",
    "- **OpenL3**: Audio embeddings using deep learning\n",
    "- **PANNs**: Large-scale Pretrained Audio Neural Networks\n",
    "\n",
    "We'll then use these embeddings to build a music recommendation system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5db17e",
   "metadata": {},
   "source": [
    "### SECTION 1 — SETUP of modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5198586e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "%conda install openl3 torch torchaudio tensorflow pandas numpy librosa scikit-learn tqdm soundfile faiss-cpu pyarrow -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877db0c3",
   "metadata": {},
   "source": [
    "### 1.3 Set Random Seed\n",
    "\n",
    "Set random seeds for reproducibility across different libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1f842b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (2.9.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.1-cp311-cp311-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx>=2.5.1 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torchvision-0.24.1-cp311-cp311-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 2.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.8/4.0 MB 2.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.8/4.0 MB 2.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 1.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 1.8/4.0 MB 1.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.6/4.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 2.6/4.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.4/4.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.7/4.0 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.9/4.0 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.9/4.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 1.1 MB/s  0:00:03\n",
      "Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: mpmath, sympy, fsspec, filelock, torchvision\n",
      "\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   ---------------------------------------- 0/5 [mpmath]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   -------- ------------------------------- 1/5 [sympy]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ---------------- ----------------------- 2/5 [fsspec]\n",
      "   ------------------------ --------------- 3/5 [filelock]\n",
      "   ------------------------ --------------- 3/5 [filelock]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   -------------------------------- ------- 4/5 [torchvision]\n",
      "   ---------------------------------------- 5/5 [torchvision]\n",
      "\n",
      "Successfully installed filelock-3.20.0 fsspec-2025.10.0 mpmath-1.3.0 sympy-1.14.0 torchvision-0.24.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ab53a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Audio embedding libraries\n",
    "import openl3\n",
    "# Similarity search\n",
    "import faiss\n",
    "\n",
    "# Utilities\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Union, List, Dict, Optional\n",
    "import json\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72cad776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"Random seed set to {RANDOM_SEED}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a79ea",
   "metadata": {},
   "source": [
    "### SECTION 2 — LOAD DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b05b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1084 tracks from track_reference_filtered.csv\n",
      "\n",
      "Columns: ['musicbrainz_id', 'title', 'artist', 'artist_id', 'album', 'album_id', 'release_date', 'country', 'length']\n",
      "\n",
      "WAV files location: rec/{musicbrainz_id}.wav\n",
      "\n",
      "First few rows:\n",
      "                         musicbrainz_id                       title  \\\n",
      "0  00b1397d-7f3e-4c59-bb42-ccd7fa17ee10  raindrops (an angel cried)   \n",
      "1  00c9dcab-4abf-47f5-9755-c5c805b779c7            Through the Wire   \n",
      "2  012e3459-b54d-49e9-b48d-d0922d295c5a            I'll Cry Instead   \n",
      "3  013a7fe3-0113-4604-a295-f74a0b88bf05        She’s Always a Woman   \n",
      "4  01564f1c-99b2-466a-a60d-4e22a5008525                       angel   \n",
      "\n",
      "            artist                                     file_path  \n",
      "0    Ariana Grande  rec\\00b1397d-7f3e-4c59-bb42-ccd7fa17ee10.wav  \n",
      "1               Ye  rec\\00c9dcab-4abf-47f5-9755-c5c805b779c7.wav  \n",
      "2      The Beatles  rec\\012e3459-b54d-49e9-b48d-d0922d295c5a.wav  \n",
      "3       Billy Joel  rec\\013a7fe3-0113-4604-a295-f74a0b88bf05.wav  \n",
      "4  Kacey Musgraves  rec\\01564f1c-99b2-466a-a60d-4e22a5008525.wav  \n"
     ]
    }
   ],
   "source": [
    "# Load the filtered CSV file (contains only records with existing WAV files)\n",
    "CSV_PATH = \"track_reference_filtered.csv\"\n",
    "\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(f\"Filtered CSV file not found: {CSV_PATH}. Please run filter_csv_by_wav_files.py first.\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Loaded {len(df)} tracks from {CSV_PATH}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "\n",
    "# Create file_path column: WAV files are in 'rec' folder, named as musicbrainz_id.wav\n",
    "REC_FOLDER = \"rec\"\n",
    "df['file_path'] = df['musicbrainz_id'].apply(lambda x: os.path.join(REC_FOLDER, f\"{x}.wav\"))\n",
    "\n",
    "print(f\"\\nWAV files location: {REC_FOLDER}/{{musicbrainz_id}}.wav\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df[['musicbrainz_id', 'title', 'artist', 'file_path']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de15d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>musicbrainz_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>album</th>\n",
       "      <th>album_id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>country</th>\n",
       "      <th>length</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00b1397d-7f3e-4c59-bb42-ccd7fa17ee10</td>\n",
       "      <td>raindrops (an angel cried)</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>f4fdbb4c-e4b7-47a0-b83b-d91bbfcfa387</td>\n",
       "      <td>sweetener / thank u, next tour - live at Coach...</td>\n",
       "      <td>6cd36f2a-0c90-45ea-b63b-0e922f1df4ba</td>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>XW</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>rec\\00b1397d-7f3e-4c59-bb42-ccd7fa17ee10.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00c9dcab-4abf-47f5-9755-c5c805b779c7</td>\n",
       "      <td>Through the Wire</td>\n",
       "      <td>Ye</td>\n",
       "      <td>164f0d73-1234-4e2c-8743-d77bf2191051</td>\n",
       "      <td>BET Awards: '04 Nominees</td>\n",
       "      <td>d9f9fa38-f06e-4d22-abf8-73b60983ef8f</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>270386.0</td>\n",
       "      <td>rec\\00c9dcab-4abf-47f5-9755-c5c805b779c7.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>012e3459-b54d-49e9-b48d-d0922d295c5a</td>\n",
       "      <td>I'll Cry Instead</td>\n",
       "      <td>The Beatles</td>\n",
       "      <td>b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d</td>\n",
       "      <td>UK EP Collection, Volume 1</td>\n",
       "      <td>51443d4d-fdb8-4d4e-8b61-58237764e6ae</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>XW</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>rec\\012e3459-b54d-49e9-b48d-d0922d295c5a.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>013a7fe3-0113-4604-a295-f74a0b88bf05</td>\n",
       "      <td>She’s Always a Woman</td>\n",
       "      <td>Billy Joel</td>\n",
       "      <td>64b94289-9474-4d43-8c93-918ccc1920d1</td>\n",
       "      <td>Retold, Volume 3: Souvenir of a Stranger at th...</td>\n",
       "      <td>c5c69643-b9d3-446b-a773-57747bc1ad08</td>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>120560.0</td>\n",
       "      <td>rec\\013a7fe3-0113-4604-a295-f74a0b88bf05.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01564f1c-99b2-466a-a60d-4e22a5008525</td>\n",
       "      <td>angel</td>\n",
       "      <td>Kacey Musgraves</td>\n",
       "      <td>d1393ecb-431b-4fde-a6ea-d769f2f040cb</td>\n",
       "      <td>star‐crossed</td>\n",
       "      <td>80ec0d1a-00cf-465c-b832-26f15b558b57</td>\n",
       "      <td>2021-09-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>rec\\01564f1c-99b2-466a-a60d-4e22a5008525.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         musicbrainz_id                       title  \\\n",
       "0  00b1397d-7f3e-4c59-bb42-ccd7fa17ee10  raindrops (an angel cried)   \n",
       "1  00c9dcab-4abf-47f5-9755-c5c805b779c7            Through the Wire   \n",
       "2  012e3459-b54d-49e9-b48d-d0922d295c5a            I'll Cry Instead   \n",
       "3  013a7fe3-0113-4604-a295-f74a0b88bf05        She’s Always a Woman   \n",
       "4  01564f1c-99b2-466a-a60d-4e22a5008525                       angel   \n",
       "\n",
       "            artist                             artist_id  \\\n",
       "0    Ariana Grande  f4fdbb4c-e4b7-47a0-b83b-d91bbfcfa387   \n",
       "1               Ye  164f0d73-1234-4e2c-8743-d77bf2191051   \n",
       "2      The Beatles  b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d   \n",
       "3       Billy Joel  64b94289-9474-4d43-8c93-918ccc1920d1   \n",
       "4  Kacey Musgraves  d1393ecb-431b-4fde-a6ea-d769f2f040cb   \n",
       "\n",
       "                                               album  \\\n",
       "0  sweetener / thank u, next tour - live at Coach...   \n",
       "1                           BET Awards: '04 Nominees   \n",
       "2                         UK EP Collection, Volume 1   \n",
       "3  Retold, Volume 3: Souvenir of a Stranger at th...   \n",
       "4                                       star‐crossed   \n",
       "\n",
       "                               album_id release_date country    length  \\\n",
       "0  6cd36f2a-0c90-45ea-b63b-0e922f1df4ba   2019-04-19      XW   36000.0   \n",
       "1  d9f9fa38-f06e-4d22-abf8-73b60983ef8f   2004-01-01      US  270386.0   \n",
       "2  51443d4d-fdb8-4d4e-8b61-58237764e6ae   2000-01-01      XW  107000.0   \n",
       "3  c5c69643-b9d3-446b-a773-57747bc1ad08   1995-01-01      US  120560.0   \n",
       "4  80ec0d1a-00cf-465c-b832-26f15b558b57   2021-09-10     NaN  140000.0   \n",
       "\n",
       "                                      file_path  \n",
       "0  rec\\00b1397d-7f3e-4c59-bb42-ccd7fa17ee10.wav  \n",
       "1  rec\\00c9dcab-4abf-47f5-9755-c5c805b779c7.wav  \n",
       "2  rec\\012e3459-b54d-49e9-b48d-d0922d295c5a.wav  \n",
       "3  rec\\013a7fe3-0113-4604-a295-f74a0b88bf05.wav  \n",
       "4  rec\\01564f1c-99b2-466a-a60d-4e22a5008525.wav  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2783407d",
   "metadata": {},
   "source": [
    "## 2.2 Filter Valid WAV Files\n",
    "\n",
    "Filter the dataset to only include tracks with valid WAV files that exist on disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e171175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating WAV files...\n",
      "\n",
      "Original tracks: 1084\n",
      "Valid tracks: 1084\n",
      "Invalid/removed tracks: 0\n",
      "\n",
      "✅ Successfully validated 1084 tracks\n",
      "\n",
      "Sample of valid tracks:\n",
      "                         musicbrainz_id                       title  \\\n",
      "0  00b1397d-7f3e-4c59-bb42-ccd7fa17ee10  raindrops (an angel cried)   \n",
      "1  00c9dcab-4abf-47f5-9755-c5c805b779c7            Through the Wire   \n",
      "2  012e3459-b54d-49e9-b48d-d0922d295c5a            I'll Cry Instead   \n",
      "3  013a7fe3-0113-4604-a295-f74a0b88bf05        She’s Always a Woman   \n",
      "4  01564f1c-99b2-466a-a60d-4e22a5008525                       angel   \n",
      "\n",
      "            artist                             artist_id  \\\n",
      "0    Ariana Grande  f4fdbb4c-e4b7-47a0-b83b-d91bbfcfa387   \n",
      "1               Ye  164f0d73-1234-4e2c-8743-d77bf2191051   \n",
      "2      The Beatles  b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d   \n",
      "3       Billy Joel  64b94289-9474-4d43-8c93-918ccc1920d1   \n",
      "4  Kacey Musgraves  d1393ecb-431b-4fde-a6ea-d769f2f040cb   \n",
      "\n",
      "                                               album  \\\n",
      "0  sweetener / thank u, next tour - live at Coach...   \n",
      "1                           BET Awards: '04 Nominees   \n",
      "2                         UK EP Collection, Volume 1   \n",
      "3  Retold, Volume 3: Souvenir of a Stranger at th...   \n",
      "4                                       star‐crossed   \n",
      "\n",
      "                               album_id release_date country    length  \\\n",
      "0  6cd36f2a-0c90-45ea-b63b-0e922f1df4ba   2019-04-19      XW   36000.0   \n",
      "1  d9f9fa38-f06e-4d22-abf8-73b60983ef8f   2004-01-01      US  270386.0   \n",
      "2  51443d4d-fdb8-4d4e-8b61-58237764e6ae   2000-01-01      XW  107000.0   \n",
      "3  c5c69643-b9d3-446b-a773-57747bc1ad08   1995-01-01      US  120560.0   \n",
      "4  80ec0d1a-00cf-465c-b832-26f15b558b57   2021-09-10     NaN  140000.0   \n",
      "\n",
      "                                      file_path  \n",
      "0  rec\\00b1397d-7f3e-4c59-bb42-ccd7fa17ee10.wav  \n",
      "1  rec\\00c9dcab-4abf-47f5-9755-c5c805b779c7.wav  \n",
      "2  rec\\012e3459-b54d-49e9-b48d-d0922d295c5a.wav  \n",
      "3  rec\\013a7fe3-0113-4604-a295-f74a0b88bf05.wav  \n",
      "4  rec\\01564f1c-99b2-466a-a60d-4e22a5008525.wav  \n"
     ]
    }
   ],
   "source": [
    "def validate_wav_file(file_path: str) -> bool:\n",
    "    \"\"\"Check if a WAV file exists and is readable.\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            return False\n",
    "        # Try to load the file to ensure it's valid\n",
    "        data, sr = librosa.load(file_path, sr=None, duration=1.0)\n",
    "        return len(data) > 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error validating {file_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Filter tracks with valid WAV files\n",
    "print(\"Validating WAV files...\")\n",
    "valid_mask = df['file_path'].apply(validate_wav_file)\n",
    "df_valid = df[valid_mask].copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nOriginal tracks: {len(df)}\")\n",
    "print(f\"Valid tracks: {len(df_valid)}\")\n",
    "print(f\"Invalid/removed tracks: {len(df) - len(df_valid)}\")\n",
    "\n",
    "if len(df_valid) == 0:\n",
    "    print(\"\\n⚠️  WARNING: No valid WAV files found!\")\n",
    "    print(\"Please update the CSV_PATH and ensure file_paths in the CSV are correct.\")\n",
    "else:\n",
    "    print(f\"\\n✅ Successfully validated {len(df_valid)} tracks\")\n",
    "    print(\"\\nSample of valid tracks:\")\n",
    "    print(df_valid.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d8ce6",
   "metadata": {},
   "source": [
    "### SECTION 3 — AUDIO EMBEDDING MODELS using OpenL3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac994a",
   "metadata": {},
   "source": [
    "#### 3.1 OpenL3 Embedding Model\n",
    "\n",
    "OpenL3 is a deep learning model for audio embeddings that uses a combination of audio and visual information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58ca53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenL3Embedding:\n",
    "    \"\"\"OpenL3 audio embedding model wrapper.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_repr=\"mel256\", content_type=\"music\", embedding_size=512):\n",
    "        \"\"\"\n",
    "        Initialize OpenL3 model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        input_repr : str\n",
    "            Input representation: \"linear\", \"mel128\", or \"mel256\"\n",
    "        content_type : str\n",
    "            Content type: \"music\" or \"env\"\n",
    "        embedding_size : int\n",
    "            Embedding size: 512 or 6144\n",
    "        \"\"\"\n",
    "        self.input_repr = input_repr\n",
    "        self.content_type = content_type\n",
    "        self.embedding_size = embedding_size\n",
    "        self.model = None\n",
    "        print(f\"OpenL3Embedding initialized with input_repr={input_repr}, \"\n",
    "              f\"content_type={content_type}, embedding_size={embedding_size}\")\n",
    "    \n",
    "    def get_embedding(self, wav_path: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract embedding from audio file.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        wav_path : str\n",
    "            Path to WAV file\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Audio embedding vector\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load audio file\n",
    "            audio, sr = librosa.load(wav_path, sr=48000)  # OpenL3 expects 48kHz\n",
    "            \n",
    "            # Get embedding using OpenL3\n",
    "            # OpenL3 returns embeddings with shape (n_frames, embedding_size)\n",
    "            # We'll take the mean across frames to get a single vector\n",
    "            embedding, _ = openl3.get_audio_embedding(\n",
    "                audio,\n",
    "                sr,\n",
    "                input_repr=self.input_repr,\n",
    "                content_type=self.content_type,\n",
    "                embedding_size=self.embedding_size,\n",
    "                center=True,\n",
    "                hop_size=0.1,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            # Average over time frames to get a single embedding vector\n",
    "            if len(embedding.shape) > 1:\n",
    "                embedding = np.mean(embedding, axis=0)\n",
    "            \n",
    "            return embedding.astype(np.float32)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting OpenL3 embedding from {wav_path}: {e}\")\n",
    "            # Return zero vector of correct size as fallback\n",
    "            return np.zeros(self.embedding_size, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79c119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting panns_inference\n",
      "  Downloading panns_inference-0.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting matplotlib (from panns_inference)\n",
      "  Downloading matplotlib-3.10.7-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: librosa in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from panns_inference) (0.11.0)\n",
      "Requirement already satisfied: torchlibrosa in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from panns_inference) (0.1.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (0.62.1)\n",
      "Requirement already satisfied: numpy>=1.22.3 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (4.15.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from librosa->panns_inference) (1.1.2)\n",
      "Requirement already satisfied: packaging in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from lazy_loader>=0.1->librosa->panns_inference) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from numba>=0.51.0->librosa->panns_inference) (0.45.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from pooch>=1.1->librosa->panns_inference) (4.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from pooch>=1.1->librosa->panns_inference) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa->panns_inference) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa->panns_inference) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa->panns_inference) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa->panns_inference) (2025.11.12)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from scikit-learn>=1.1.0->librosa->panns_inference) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from soundfile>=0.12.1->librosa->panns_inference) (2.0.0)\n",
      "Requirement already satisfied: pycparser in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->panns_inference) (2.23)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->panns_inference)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->panns_inference)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->panns_inference)\n",
      "  Downloading fonttools-4.60.1-cp311-cp311-win_amd64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->panns_inference)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pillow>=8 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from matplotlib->panns_inference) (11.3.0)\n",
      "Collecting pyparsing>=3 (from matplotlib->panns_inference)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from matplotlib->panns_inference) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\rec-music-recommendation-system\\wav-embedidng-recommendation-logic\\.conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->panns_inference) (1.17.0)\n",
      "Downloading panns_inference-0.1.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading matplotlib-3.10.7-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.0/8.1 MB 5.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.1/8.1 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.9/8.1 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.2/8.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.0/8.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.0/8.1 MB 4.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.8/8.1 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.9/8.1 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 4.7 MB/s  0:00:01\n",
      "Downloading contourpy-1.3.3-cp311-cp311-win_amd64.whl (225 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.3 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 4.2 MB/s  0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp311-cp311-win_amd64.whl (73 kB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, panns_inference\n",
      "\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ----------- ---------------------------- 2/7 [fonttools]\n",
      "   ---------------------- ----------------- 4/7 [contourpy]\n",
      "   ---------------------- ----------------- 4/7 [contourpy]\n",
      "   ---------------------- ----------------- 4/7 [contourpy]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------- ----------- 5/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [panns_inference]\n",
      "   ---------------------------------------- 7/7 [panns_inference]\n",
      "\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 panns_inference-0.1.1 pyparsing-3.2.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install panns_inference for PANNs model support\n",
    "# Uncomment the line below if panns_inference is not installed\n",
    "%pip install panns_inference Pillow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91894b7",
   "metadata": {},
   "source": [
    "### 3.3 PANNs Embedding Model\n",
    "\n",
    "PANNs (Pretrained Audio Neural Networks) are large-scale pretrained models for audio classification and feature extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1eeabb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL.PngImagePlugin'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpanns_inference\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\rec-music-recommendation-system\\WAV-Embedidng-Recommendation-Logic\\.conda\\Lib\\site-packages\\panns_inference\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AudioTagging, SoundEventDetection\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m labels\n\u001b[32m      4\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m0.1.0\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\rec-music-recommendation-system\\WAV-Embedidng-Recommendation-Logic\\.conda\\Lib\\site-packages\\panns_inference\\inference.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01margparse\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\rec-music-recommendation-system\\WAV-Embedidng-Recommendation-Logic\\.conda\\Lib\\site-packages\\matplotlib\\__init__.py:161\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrcsetup\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\rec-music-recommendation-system\\WAV-Embedidng-Recommendation-Logic\\.conda\\Lib\\site-packages\\matplotlib\\rcsetup.py:28\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_fontconfig_pattern\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_enums\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\rec-music-recommendation-system\\WAV-Embedidng-Recommendation-Logic\\.conda\\Lib\\site-packages\\matplotlib\\colors.py:53\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mPngImagePlugin\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PngInfo\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpl\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'PIL.PngImagePlugin'"
     ]
    }
   ],
   "source": [
    "import panns_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76aa186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PANNsEmbedding:\n",
    "    \"\"\"PANNs audio embedding model wrapper.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize PANNs model using torchaudio pretrained pipeline.\"\"\"\n",
    "        print(\"Loading PANNs model...\")\n",
    "        try:\n",
    "            # Load PANNs pipeline from torchaudio\n",
    "            self.pipeline = torchaudio.pipelines.PANNs_CNNonly()\n",
    "            self.model = self.pipeline.get_model()\n",
    "            self.model.eval()\n",
    "            self.sample_rate = self.pipeline.sample_rate\n",
    "            print(f\"✅ PANNs model loaded successfully (sample_rate={self.sample_rate})\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Error loading PANNs model: {e}\")\n",
    "            print(\"Attempting alternative loading method...\")\n",
    "            try:\n",
    "                # Alternative: try the full PANNs model\n",
    "                self.pipeline = torchaudio.pipelines.PANNs_AS20K()\n",
    "                self.model = self.pipeline.get_model()\n",
    "                self.model.eval()\n",
    "                self.sample_rate = self.pipeline.sample_rate\n",
    "                print(f\"✅ PANNs model loaded successfully (sample_rate={self.sample_rate})\")\n",
    "            except Exception as e2:\n",
    "                print(f\"❌ Failed to load PANNs model: {e2}\")\n",
    "                self.model = None\n",
    "                self.sample_rate = 32000\n",
    "    \n",
    "    def _preprocess_audio(self, wav_path: str) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Preprocess audio file for PANNs.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        wav_path : str\n",
    "            Path to WAV file\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        torch.Tensor\n",
    "            Preprocessed audio tensor\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load audio\n",
    "            waveform, sample_rate = torchaudio.load(wav_path)\n",
    "            \n",
    "            # Resample if necessary\n",
    "            if sample_rate != self.sample_rate:\n",
    "                resampler = torchaudio.transforms.Resample(sample_rate, self.sample_rate)\n",
    "                waveform = resampler(waveform)\n",
    "            \n",
    "            # Convert to mono if stereo\n",
    "            if waveform.shape[0] > 1:\n",
    "                waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "            \n",
    "            return waveform\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error preprocessing audio {wav_path}: {e}\")\n",
    "            return torch.zeros(1, self.sample_rate * 10)  # 10 seconds of zeros\n",
    "    \n",
    "    def get_embedding(self, wav_path: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract embedding from audio file.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        wav_path : str\n",
    "            Path to WAV file\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray\n",
    "            Audio embedding vector (2048D)\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            print(\"PANNs model not loaded, returning zero vector\")\n",
    "            return np.zeros(2048, dtype=np.float32)\n",
    "        \n",
    "        try:\n",
    "            # Preprocess audio\n",
    "            waveform = self._preprocess_audio(wav_path)\n",
    "            \n",
    "            # Get embedding\n",
    "            with torch.no_grad():\n",
    "                # Forward pass through the model\n",
    "                # PANNs model typically returns features from an intermediate layer\n",
    "                # We need to extract the embedding layer output (before classification head)\n",
    "                \n",
    "                # Get the feature extractor part of the model\n",
    "                # The model structure may vary, so we'll try to get embeddings\n",
    "                # by accessing intermediate layers\n",
    "                \n",
    "                # Method 1: Try to get features directly if model supports it\n",
    "                if hasattr(self.model, 'get_embedding'):\n",
    "                    embedding = self.model.get_embedding(waveform)\n",
    "                else:\n",
    "                    # Method 2: Forward pass and extract intermediate features\n",
    "                    # Most PANNs models have a feature extractor that outputs 2048D\n",
    "                    features = self.model(waveform)\n",
    "                    \n",
    "                    # If features is a tuple, take the first element (embeddings)\n",
    "                    if isinstance(features, tuple):\n",
    "                        embedding = features[0]\n",
    "                    else:\n",
    "                        embedding = features\n",
    "                    \n",
    "                    # If the output is 2D (batch, features), take the first sample\n",
    "                    if len(embedding.shape) > 1:\n",
    "                        embedding = embedding[0] if embedding.shape[0] == 1 else embedding.mean(dim=0)\n",
    "                \n",
    "                # Convert to numpy\n",
    "                if isinstance(embedding, torch.Tensor):\n",
    "                    embedding = embedding.cpu().numpy()\n",
    "                \n",
    "                # Ensure correct dimensionality (2048D)\n",
    "                if embedding.shape[0] != 2048:\n",
    "                    if embedding.shape[0] < 2048:\n",
    "                        embedding = np.pad(embedding, (0, 2048 - embedding.shape[0]))\n",
    "                    else:\n",
    "                        embedding = embedding[:2048]\n",
    "                \n",
    "                return embedding.astype(np.float32)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting PANNs embedding from {wav_path}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return np.zeros(2048, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba711ac",
   "metadata": {},
   "source": [
    "#### 3.4 Audio Embedding Factory\n",
    "\n",
    "Factory class to create and manage different embedding models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "337909c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available embedding models:\n",
      "['openl3', 'panns']\n",
      "\n",
      "Embedding dimensions:\n",
      "  openl3: 512D\n",
      "  panns: 2048D\n"
     ]
    }
   ],
   "source": [
    "class AudioEmbeddingFactory:\n",
    "    \"\"\"Factory class for creating audio embedding models.\"\"\"\n",
    "    \n",
    "    _models = {\n",
    "        \"openl3\": OpenL3Embedding,\n",
    "        \"panns\": PANNsEmbedding\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def create_model(cls, model_type: str, **kwargs):\n",
    "        \"\"\"\n",
    "        Create an audio embedding model instance.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_type : str\n",
    "            Type of model: \"openl3\" or \"panns\"\n",
    "        **kwargs\n",
    "            Additional arguments to pass to the model constructor\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        Embedding model instance\n",
    "        \"\"\"\n",
    "        model_type = model_type.lower()\n",
    "        \n",
    "        if model_type not in cls._models:\n",
    "            raise ValueError(\n",
    "                f\"Unknown model type: {model_type}. \"\n",
    "                f\"Available models: {list(cls._models.keys())}\"\n",
    "            )\n",
    "        \n",
    "        model_class = cls._models[model_type]\n",
    "        return model_class(**kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_available_models(cls):\n",
    "        \"\"\"Get list of available model types.\"\"\"\n",
    "        return list(cls._models.keys())\n",
    "    \n",
    "    @classmethod\n",
    "    def get_embedding_dimension(cls, model_type: str) -> int:\n",
    "        \"\"\"\n",
    "        Get the embedding dimension for a given model type.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        model_type : str\n",
    "            Type of model\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        int\n",
    "            Embedding dimension\n",
    "        \"\"\"\n",
    "        dimensions = {\n",
    "            \"openl3\": 512,\n",
    "                        \"panns\": 2048\n",
    "        }\n",
    "        return dimensions.get(model_type.lower(), 512)\n",
    "\n",
    "# Test the factory\n",
    "print(\"Available embedding models:\")\n",
    "print(AudioEmbeddingFactory.get_available_models())\n",
    "print(\"\\nEmbedding dimensions:\")\n",
    "for model_type in AudioEmbeddingFactory.get_available_models():\n",
    "    dim = AudioEmbeddingFactory.get_embedding_dimension(model_type)\n",
    "    print(f\"  {model_type}: {dim}D\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272b5b82",
   "metadata": {},
   "source": [
    "\n",
    "### SECTION 4 — COMPUTE EMBEDDINGS FOR 10 RANDOM SONGS\n",
    "\n",
    "\n",
    "We'll randomly sample 10 songs from the dataset and compute embeddings using both models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a8923",
   "metadata": {},
   "source": [
    "#### 4.1 Sample 10 Random Songs\n",
    "\n",
    "Randomly select 10 songs from the validated dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7161a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>musicbrainz_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>album</th>\n",
       "      <th>album_id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>country</th>\n",
       "      <th>length</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>aafe72e2-9b95-41db-b1d5-599bc21ecdfe</td>\n",
       "      <td>She's Leaving Home</td>\n",
       "      <td>The Beatles</td>\n",
       "      <td>b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d</td>\n",
       "      <td>Sgt. Pepper Naked</td>\n",
       "      <td>e5f85542-4987-4c41-8b8d-36daf0a3d118</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>216456.0</td>\n",
       "      <td>rec\\aafe72e2-9b95-41db-b1d5-599bc21ecdfe.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0c1481db-8f8f-46ba-ba51-a238617c62b1</td>\n",
       "      <td>my hair</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>f4fdbb4c-e4b7-47a0-b83b-d91bbfcfa387</td>\n",
       "      <td>my hair</td>\n",
       "      <td>e4958a84-b691-4f90-a82b-880abc67aef6</td>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>XW</td>\n",
       "      <td>197000.0</td>\n",
       "      <td>rec\\0c1481db-8f8f-46ba-ba51-a238617c62b1.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           musicbrainz_id               title         artist  \\\n",
       "693  aafe72e2-9b95-41db-b1d5-599bc21ecdfe  She's Leaving Home    The Beatles   \n",
       "56   0c1481db-8f8f-46ba-ba51-a238617c62b1             my hair  Ariana Grande   \n",
       "\n",
       "                                artist_id              album  \\\n",
       "693  b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d  Sgt. Pepper Naked   \n",
       "56   f4fdbb4c-e4b7-47a0-b83b-d91bbfcfa387            my hair   \n",
       "\n",
       "                                 album_id release_date country    length  \\\n",
       "693  e5f85542-4987-4c41-8b8d-36daf0a3d118   2005-01-01      US  216456.0   \n",
       "56   e4958a84-b691-4f90-a82b-880abc67aef6   2021-07-14      XW  197000.0   \n",
       "\n",
       "                                        file_path  \n",
       "693  rec\\aafe72e2-9b95-41db-b1d5-599bc21ecdfe.wav  \n",
       "56   rec\\0c1481db-8f8f-46ba-ba51-a238617c62b1.wav  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cac35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sampled 10 songs from 1084 total tracks\n",
      "\n",
      "Sampled tracks:\n",
      "                         musicbrainz_id  \\\n",
      "0  2e9ff3e6-9c69-4675-a249-abcf05241811   \n",
      "1  dddaf5be-1342-438b-9f47-2dbc470cc7ee   \n",
      "2  1b85a6a7-0175-4bf1-ba75-9dc7f5505689   \n",
      "3  9a7c7ee2-6b9e-461d-bab0-c273c6997461   \n",
      "4  a1f25623-f56c-4f36-bcce-67488d04e7cc   \n",
      "5  02159dd4-018a-4264-acca-19d2edc233d2   \n",
      "6  242d99f7-5b74-44db-928e-94ccc14845a4   \n",
      "7  045ccc99-34d4-4c23-90a9-1c16101e86bb   \n",
      "8  2fedfd5e-d88e-458c-9890-0265e8c41a8c   \n",
      "9  7b01bee3-dd37-4221-8535-3792f5e9280e   \n",
      "\n",
      "                                      file_path                       title  \\\n",
      "0  rec\\2e9ff3e6-9c69-4675-a249-abcf05241811.wav                  fake smile   \n",
      "1  rec\\dddaf5be-1342-438b-9f47-2dbc470cc7ee.wav               The Lucky One   \n",
      "2  rec\\1b85a6a7-0175-4bf1-ba75-9dc7f5505689.wav                       prfct   \n",
      "3  rec\\9a7c7ee2-6b9e-461d-bab0-c273c6997461.wav    I Saw Her Standing There   \n",
      "4  rec\\a1f25623-f56c-4f36-bcce-67488d04e7cc.wav               White Ferrari   \n",
      "5  rec\\02159dd4-018a-4264-acca-19d2edc233d2.wav    SWEET ★ HONEY ★ BUCKIIN’   \n",
      "6  rec\\242d99f7-5b74-44db-928e-94ccc14845a4.wav        Just the Way You Are   \n",
      "7  rec\\045ccc99-34d4-4c23-90a9-1c16101e86bb.wav  I Should Have Known Better   \n",
      "8  rec\\2fedfd5e-d88e-458c-9890-0265e8c41a8c.wav                        Mine   \n",
      "9  rec\\7b01bee3-dd37-4221-8535-3792f5e9280e.wav      Within You Without You   \n",
      "\n",
      "              artist  \n",
      "0      Ariana Grande  \n",
      "1       Taylor Swift  \n",
      "2  Sabrina Carpenter  \n",
      "3        The Beatles  \n",
      "4        Frank Ocean  \n",
      "5            Beyoncé  \n",
      "6         Billy Joel  \n",
      "7        The Beatles  \n",
      "8       Taylor Swift  \n",
      "9        The Beatles  \n"
     ]
    }
   ],
   "source": [
    "# Sample 10 random songs from the validated dataset\n",
    "N_SAMPLES = 10\n",
    "\n",
    "if len(df_valid) >= N_SAMPLES:\n",
    "    df_sample = df_valid.sample(n=N_SAMPLES, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "    print(f\"✅ Sampled {len(df_sample)} songs from {len(df_valid)} total tracks\")\n",
    "    print(\"\\nSampled tracks:\")\n",
    "    print(df_sample[['musicbrainz_id', 'file_path', 'title', 'artist']].head(10))\n",
    "else:\n",
    "    print(f\"⚠️  Only {len(df_valid)} tracks available, using all of them\")\n",
    "    df_sample = df_valid.copy()\n",
    "    print(\"\\nUsing all available tracks:\")\n",
    "    print(df_sample[['musicbrainz_id', 'file_path']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d390cf",
   "metadata": {},
   "source": [
    "#### 4.2 Compute Embeddings for both models\n",
    "\n",
    "Generate embeddings for the sampled songs using OpenL3 and PANNs models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1a272572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting embedding computation for all models...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Computing OPENL3 embeddings...\n",
      "============================================================\n",
      "OpenL3Embedding initialized with input_repr=mel256, content_type=music, embedding_size=512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing openl3: 100%|██████████| 10/10 [22:09<00:00, 132.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully computed 10 OPENL3 embeddings\n",
      "\n",
      "============================================================\n",
      "✅ All embeddings computed successfully!\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_embeddings_for_model(\n",
    "    df: pd.DataFrame,\n",
    "    model_type: str,\n",
    "    **model_kwargs\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute embeddings for all tracks in dataframe using specified model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe with 'musicbrainz_id' and 'file_path' columns\n",
    "    model_type : str\n",
    "        Type of embedding model: \"openl3\" or \"panns\"\n",
    "    **model_kwargs\n",
    "        Additional arguments for model initialization\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Dict[str, np.ndarray]\n",
    "        Dictionary mapping musicbrainz_id to embedding vector\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Computing {model_type.upper()} embeddings...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create model instance\n",
    "    model = AudioEmbeddingFactory.create_model(model_type, **model_kwargs)\n",
    "    \n",
    "    # Dictionary to store embeddings: {musicbrainz_id: embedding_vector}\n",
    "    embeddings_dict = {}\n",
    "    \n",
    "    # Process each track\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {model_type}\"):\n",
    "        musicbrainz_id = row['musicbrainz_id']\n",
    "        wav_path = row['file_path']\n",
    "        \n",
    "        try:\n",
    "            embedding = model.get_embedding(wav_path)\n",
    "            embeddings_dict[musicbrainz_id] = embedding\n",
    "        except Exception as e:\n",
    "            print(f\"\\n⚠️  Error processing {musicbrainz_id}: {e}\")\n",
    "            # Store zero vector as fallback\n",
    "            embedding_dim = AudioEmbeddingFactory.get_embedding_dimension(model_type)\n",
    "            embeddings_dict[musicbrainz_id] = np.zeros(embedding_dim, dtype=np.float32)\n",
    "    \n",
    "    print(f\"✅ Successfully computed {len(embeddings_dict)} {model_type.upper()} embeddings\")\n",
    "    return embeddings_dict\n",
    "\n",
    "# Compute embeddings for both models\n",
    "print(\"Starting embedding computation for all models...\\n\")\n",
    "\n",
    "# OpenL3 embeddings\n",
    "openl3_embeddings = compute_embeddings_for_model(df_sample, \"openl3\")\n",
    "\n",
    "# PANNs embeddings\n",
    "## TODO: Pann embeddings do not work\n",
    "# panns_embeddings = compute_embeddings_for_model(df_sample, \"panns\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ All embeddings computed successfully!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda330f8",
   "metadata": {},
   "source": [
    "## 4.3 Save Embeddings to Parquet Files\n",
    "\n",
    "Convert embeddings dictionaries to DataFrames and save as Parquet files for efficient storage and retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffc7083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_to_parquet(\n",
    "    embeddings_dict: Dict[str, np.ndarray],\n",
    "    df_metadata: pd.DataFrame,\n",
    "    output_path: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert embeddings dictionary to DataFrame and save as Parquet.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    embeddings_dict : Dict[str, np.ndarray]\n",
    "        Dictionary mapping musicbrainz_id to embedding vector\n",
    "    df_metadata : pd.DataFrame\n",
    "        Dataframe with track metadata\n",
    "    output_path : str\n",
    "        Path to save Parquet file\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with embeddings and metadata\n",
    "    \"\"\"\n",
    "    # Create list of records\n",
    "    records = []\n",
    "    for musicbrainz_id, embedding in embeddings_dict.items():\n",
    "        # Get metadata for this track\n",
    "        track_meta = df_metadata[df_metadata['musicbrainz_id'] == musicbrainz_id].iloc[0].to_dict()\n",
    "        \n",
    "        # Create record with embedding as list (Parquet-friendly)\n",
    "        record = track_meta.copy()\n",
    "        record['embedding'] = embedding.tolist()\n",
    "        records.append(record)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_embeddings = pd.DataFrame(records)\n",
    "    \n",
    "    # Save to Parquet\n",
    "    df_embeddings.to_parquet(output_path, index=False)\n",
    "    print(f\"💾 Saved {len(df_embeddings)} embeddings to {output_path}\")\n",
    "    print(f\"   Embedding dimension: {len(embeddings_dict[list(embeddings_dict.keys())[0]])}D\")\n",
    "    \n",
    "    return df_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b2b38ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving embeddings to Parquet files...\n",
      "\n",
      "💾 Saved 10 embeddings to openl3_embeddings2.parquet\n",
      "   Embedding dimension: 512D\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings for each model\n",
    "print(\"Saving embeddings to Parquet files...\\n\")\n",
    "\n",
    "df_openl3 = save_embeddings_to_parquet(\n",
    "    openl3_embeddings,\n",
    "    df_sample,\n",
    "    \"openl3_embeddings2.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8d746d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>musicbrainz_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>album</th>\n",
       "      <th>album_id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>country</th>\n",
       "      <th>length</th>\n",
       "      <th>file_path</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e9ff3e6-9c69-4675-a249-abcf05241811</td>\n",
       "      <td>fake smile</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>f4fdbb4c-e4b7-47a0-b83b-d91bbfcfa387</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>f3c1f76d-d436-4402-8888-1fdcf9e6cba8</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>US</td>\n",
       "      <td>208000.0</td>\n",
       "      <td>rec\\2e9ff3e6-9c69-4675-a249-abcf05241811.wav</td>\n",
       "      <td>[2.497593641281128, 2.0696356296539307, 3.4409...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dddaf5be-1342-438b-9f47-2dbc470cc7ee</td>\n",
       "      <td>The Lucky One</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>20244d07-534f-4eff-b4d4-930878889970</td>\n",
       "      <td>The Red Tour Live</td>\n",
       "      <td>8963a851-256d-4645-8bc7-245f6e3990ed</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235000.0</td>\n",
       "      <td>rec\\dddaf5be-1342-438b-9f47-2dbc470cc7ee.wav</td>\n",
       "      <td>[2.5221030712127686, 2.1559553146362305, 2.695...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1b85a6a7-0175-4bf1-ba75-9dc7f5505689</td>\n",
       "      <td>prfct</td>\n",
       "      <td>Sabrina Carpenter</td>\n",
       "      <td>1882fe91-cdd9-49c9-9956-8e06a3810bd4</td>\n",
       "      <td>Singular: Act I</td>\n",
       "      <td>2600e60d-cf59-4af3-9d60-dcbdd7f78a50</td>\n",
       "      <td>2018-11-09</td>\n",
       "      <td>XW</td>\n",
       "      <td>166000.0</td>\n",
       "      <td>rec\\1b85a6a7-0175-4bf1-ba75-9dc7f5505689.wav</td>\n",
       "      <td>[2.575032949447632, 2.299551010131836, 3.51459...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9a7c7ee2-6b9e-461d-bab0-c273c6997461</td>\n",
       "      <td>I Saw Her Standing There</td>\n",
       "      <td>The Beatles</td>\n",
       "      <td>b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d</td>\n",
       "      <td>Chronology, Volume 4: Yesterday (1965-1966)</td>\n",
       "      <td>3f60adc0-f72b-44d5-8367-02a9167355b5</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>AU</td>\n",
       "      <td>220840.0</td>\n",
       "      <td>rec\\9a7c7ee2-6b9e-461d-bab0-c273c6997461.wav</td>\n",
       "      <td>[2.2790493965148926, 2.121922731399536, 2.5437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1f25623-f56c-4f36-bcce-67488d04e7cc</td>\n",
       "      <td>White Ferrari</td>\n",
       "      <td>Frank Ocean</td>\n",
       "      <td>e520459c-dff4-491d-a6e4-c97be35e0044</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>8294645a-f996-44b6-9060-7f189b9f59f3</td>\n",
       "      <td>2016-08-20</td>\n",
       "      <td>XW</td>\n",
       "      <td>249000.0</td>\n",
       "      <td>rec\\a1f25623-f56c-4f36-bcce-67488d04e7cc.wav</td>\n",
       "      <td>[2.3905208110809326, 1.8205856084823608, 2.546...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         musicbrainz_id                     title  \\\n",
       "0  2e9ff3e6-9c69-4675-a249-abcf05241811                fake smile   \n",
       "1  dddaf5be-1342-438b-9f47-2dbc470cc7ee             The Lucky One   \n",
       "2  1b85a6a7-0175-4bf1-ba75-9dc7f5505689                     prfct   \n",
       "3  9a7c7ee2-6b9e-461d-bab0-c273c6997461  I Saw Her Standing There   \n",
       "4  a1f25623-f56c-4f36-bcce-67488d04e7cc             White Ferrari   \n",
       "\n",
       "              artist                             artist_id  \\\n",
       "0      Ariana Grande  f4fdbb4c-e4b7-47a0-b83b-d91bbfcfa387   \n",
       "1       Taylor Swift  20244d07-534f-4eff-b4d4-930878889970   \n",
       "2  Sabrina Carpenter  1882fe91-cdd9-49c9-9956-8e06a3810bd4   \n",
       "3        The Beatles  b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d   \n",
       "4        Frank Ocean  e520459c-dff4-491d-a6e4-c97be35e0044   \n",
       "\n",
       "                                         album  \\\n",
       "0                                thank u, next   \n",
       "1                            The Red Tour Live   \n",
       "2                              Singular: Act I   \n",
       "3  Chronology, Volume 4: Yesterday (1965-1966)   \n",
       "4                                       Blonde   \n",
       "\n",
       "                               album_id release_date country    length  \\\n",
       "0  f3c1f76d-d436-4402-8888-1fdcf9e6cba8   2019-02-07      US  208000.0   \n",
       "1  8963a851-256d-4645-8bc7-245f6e3990ed   2014-01-01     NaN  235000.0   \n",
       "2  2600e60d-cf59-4af3-9d60-dcbdd7f78a50   2018-11-09      XW  166000.0   \n",
       "3  3f60adc0-f72b-44d5-8367-02a9167355b5   1994-01-01      AU  220840.0   \n",
       "4  8294645a-f996-44b6-9060-7f189b9f59f3   2016-08-20      XW  249000.0   \n",
       "\n",
       "                                      file_path  \\\n",
       "0  rec\\2e9ff3e6-9c69-4675-a249-abcf05241811.wav   \n",
       "1  rec\\dddaf5be-1342-438b-9f47-2dbc470cc7ee.wav   \n",
       "2  rec\\1b85a6a7-0175-4bf1-ba75-9dc7f5505689.wav   \n",
       "3  rec\\9a7c7ee2-6b9e-461d-bab0-c273c6997461.wav   \n",
       "4  rec\\a1f25623-f56c-4f36-bcce-67488d04e7cc.wav   \n",
       "\n",
       "                                           embedding  \n",
       "0  [2.497593641281128, 2.0696356296539307, 3.4409...  \n",
       "1  [2.5221030712127686, 2.1559553146362305, 2.695...  \n",
       "2  [2.575032949447632, 2.299551010131836, 3.51459...  \n",
       "3  [2.2790493965148926, 2.121922731399536, 2.5437...  \n",
       "4  [2.3905208110809326, 1.8205856084823608, 2.546...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openl3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5926caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## NOT running due to inability of PANNs model to run\n",
    "# df_panns = save_embeddings_to_parquet(\n",
    "#     panns_embeddings,\n",
    "#     df_sample,\n",
    "#     \"panns_embeddings.parquet\"\n",
    "# )\n",
    "\n",
    "# print(\"\\n✅ All embeddings saved successfully!\")\n",
    "# print(\"\\nSample of saved embeddings structure:\")\n",
    "# print(df_openl3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c566a0b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba8e869c",
   "metadata": {},
   "source": [
    "#### 5.1 Recommendation System Class\n",
    "\n",
    "Create a recommendation system using FAISS for fast similarity search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a8f6fb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RecommendationEngine class defined\n"
     ]
    }
   ],
   "source": [
    "class AudioRecommendationEngine:\n",
    "    \"\"\"FAISS-based recommendation engine for audio embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings_dict: Dict[str, np.ndarray], df_metadata: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Initialize recommendation engine.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        embeddings_dict : Dict[str, np.ndarray]\n",
    "            Dictionary mapping musicbrainz_id to embedding vector\n",
    "        df_metadata : pd.DataFrame\n",
    "            Dataframe with track metadata\n",
    "        \"\"\"\n",
    "        self.embeddings_dict = embeddings_dict\n",
    "        self.df_metadata = df_metadata\n",
    "        self.musicbrainz_ids = list(embeddings_dict.keys())\n",
    "        self.index = None\n",
    "        self.embedding_dim = None\n",
    "        self._build_index()\n",
    "    \n",
    "    def _build_index(self):\n",
    "        \"\"\"Build FAISS index from embeddings.\"\"\"\n",
    "        if len(self.embeddings_dict) == 0:\n",
    "            raise ValueError(\"No embeddings provided\")\n",
    "        \n",
    "        # Get embedding dimension\n",
    "        first_embedding = list(self.embeddings_dict.values())[0]\n",
    "        self.embedding_dim = len(first_embedding)\n",
    "        \n",
    "        # Convert embeddings to numpy array\n",
    "        embeddings_array = np.array([self.embeddings_dict[tid] for tid in self.musicbrainz_ids], dtype=np.float32)\n",
    "        \n",
    "        # Normalize embeddings for cosine similarity\n",
    "        faiss.normalize_L2(embeddings_array)\n",
    "        \n",
    "        # Create FAISS index (using Inner Product for cosine similarity after normalization)\n",
    "        self.index = faiss.IndexFlatIP(self.embedding_dim)\n",
    "        self.index.add(embeddings_array)\n",
    "        \n",
    "        print(f\"✅ Built FAISS index with {self.index.ntotal} vectors (dim={self.embedding_dim})\")\n",
    "    \n",
    "    def get_recommendations(\n",
    "        self,\n",
    "        query_musicbrainz_id: str,\n",
    "        top_k: int = 5,\n",
    "        exclude_query: bool = True\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get top-k similar tracks for a given query track.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        query_musicbrainz_id : str\n",
    "            Track ID to find similar tracks for\n",
    "        top_k : int\n",
    "            Number of recommendations to return\n",
    "        exclude_query : bool\n",
    "            Whether to exclude the query track from results\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            DataFrame with recommendations including musicbrainz_id, similarity score, and metadata\n",
    "        \"\"\"\n",
    "        if query_musicbrainz_id not in self.embeddings_dict:\n",
    "            raise ValueError(f\"Track ID {query_musicbrainz_id} not found in embeddings\")\n",
    "        \n",
    "        # Get query embedding\n",
    "        query_embedding = self.embeddings_dict[query_musicbrainz_id].astype(np.float32).reshape(1, -1)\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        # Search for similar tracks\n",
    "        k = top_k + 1 if exclude_query else top_k  # +1 to account for excluding query\n",
    "        distances, indices = self.index.search(query_embedding, k)\n",
    "        \n",
    "        # Prepare results\n",
    "        results = []\n",
    "        for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "            if idx >= len(self.musicbrainz_ids):\n",
    "                continue\n",
    "            \n",
    "            recommended_musicbrainz_id = self.musicbrainz_ids[idx]\n",
    "            \n",
    "            # Skip query track if exclude_query is True\n",
    "            if exclude_query and recommended_musicbrainz_id == query_musicbrainz_id:\n",
    "                continue\n",
    "            \n",
    "            # Get metadata\n",
    "            track_meta = self.df_metadata[self.df_metadata['musicbrainz_id'] == recommended_musicbrainz_id]\n",
    "            if len(track_meta) > 0:\n",
    "                result = track_meta.iloc[0].to_dict()\n",
    "                result['similarity_score'] = float(distance)\n",
    "                result['rank'] = len(results) + 1\n",
    "                results.append(result)\n",
    "            \n",
    "            if len(results) >= top_k:\n",
    "                break\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def get_recommendations_from_embedding(\n",
    "        self,\n",
    "        query_embedding: np.ndarray,\n",
    "        top_k: int = 5\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get top-k similar tracks for a given embedding vector.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        query_embedding : np.ndarray\n",
    "            Query embedding vector\n",
    "        top_k : int\n",
    "            Number of recommendations to return\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.DataFrame\n",
    "            DataFrame with recommendations\n",
    "        \"\"\"\n",
    "        query_embedding = query_embedding.astype(np.float32).reshape(1, -1)\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        # Search\n",
    "        distances, indices = self.index.search(query_embedding, top_k)\n",
    "        \n",
    "        # Prepare results\n",
    "        results = []\n",
    "        for distance, idx in zip(distances[0], indices[0]):\n",
    "            if idx >= len(self.musicbrainz_ids):\n",
    "                continue\n",
    "            \n",
    "            recommended_musicbrainz_id = self.musicbrainz_ids[idx]\n",
    "            track_meta = self.df_metadata[self.df_metadata['musicbrainz_id'] == recommended_musicbrainz_id]\n",
    "            \n",
    "            if len(track_meta) > 0:\n",
    "                result = track_meta.iloc[0].to_dict()\n",
    "                result['similarity_score'] = float(distance)\n",
    "                result['rank'] = len(results) + 1\n",
    "                results.append(result)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "print(\"✅ RecommendationEngine class defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a52af8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1eac2796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FAISS indices for all models...\n",
      "\n",
      "✅ Built FAISS index with 10 vectors (dim=512)\n",
      "\n",
      "✅ All recommendation engines built successfully!\n"
     ]
    }
   ],
   "source": [
    "# Build recommendation engines for each model\n",
    "print(\"Building FAISS indices for all models...\\n\")\n",
    "\n",
    "rec_engine_openl3 = AudioRecommendationEngine(openl3_embeddings, df_sample)\n",
    "# rec_engine_panns = AudioRecommendationEngine(panns_embeddings, df_sample)\n",
    "\n",
    "print(\"\\n✅ All recommendation engines built successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd24d8",
   "metadata": {},
   "source": [
    "#### 5.3 Generate Recommendations for All Sampled Tracks\n",
    "\n",
    "For each of the 10 sampled tracks, get top-5 recommendations using each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b44836b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recommendations(\n",
    "    query_musicbrainz_id: str,\n",
    "    df_metadata: pd.DataFrame,\n",
    "    rec_engines: Dict[str, AudioRecommendationEngine],\n",
    "    top_k: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Display recommendations for a query track from all models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    query_musicbrainz_id : str\n",
    "        Track ID to get recommendations for\n",
    "    df_metadata : pd.DataFrame\n",
    "        Metadata dataframe\n",
    "    rec_engines : Dict[str, AudioRecommendationEngine]\n",
    "        Dictionary of recommendation engines by model name\n",
    "    top_k : int\n",
    "        Number of recommendations\n",
    "    \"\"\"\n",
    "    # Get query track info\n",
    "    query_info = df_metadata[df_metadata['musicbrainz_id'] == query_musicbrainz_id]\n",
    "    if len(query_info) == 0:\n",
    "        print(f\"⚠️  Track {query_musicbrainz_id} not found\")\n",
    "        return\n",
    "    \n",
    "    query_track = query_info.iloc[0]\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"QUERY TRACK: {query_track.get('title', 'N/A')} by {query_track.get('artist', 'N/A')}\")\n",
    "    print(f\"Track ID: {query_musicbrainz_id}\")\n",
    "    if 'genre' in query_track:\n",
    "        print(f\"Genre: {query_track['genre']}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get recommendations from each model\n",
    "    for model_name, rec_engine in rec_engines.items():\n",
    "        print(f\"\\n📊 {model_name.upper()} Recommendations (Top-{top_k}):\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        try:\n",
    "            recommendations = rec_engine.get_recommendations(query_musicbrainz_id, top_k=top_k)\n",
    "            \n",
    "            if len(recommendations) == 0:\n",
    "                print(\"  No recommendations found\")\n",
    "            else:\n",
    "                for idx, row in recommendations.iterrows():\n",
    "                    print(f\"  {row['rank']}. {row.get('title', 'N/A')} by {row.get('artist', 'N/A')}\")\n",
    "                    print(f\"     Track ID: {row['musicbrainz_id']}\")\n",
    "                    print(f\"     Similarity: {row['similarity_score']:.4f}\")\n",
    "                    if 'genre' in row:\n",
    "                        print(f\"     Genre: {row['genre']}\")\n",
    "                    print()\n",
    "        except Exception as e:\n",
    "            print(f\"  ⚠️  Error getting recommendations: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0b2e0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating recommendations for all sampled tracks...\n",
      "\n",
      "================================================================================\n",
      "QUERY TRACK: fake smile by Ariana Grande\n",
      "Track ID: 2e9ff3e6-9c69-4675-a249-abcf05241811\n",
      "================================================================================\n",
      "\n",
      "📊 OPENL3 Recommendations (Top-5):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. prfct by Sabrina Carpenter\n",
      "     Track ID: 1b85a6a7-0175-4bf1-ba75-9dc7f5505689\n",
      "     Similarity: 0.9967\n",
      "\n",
      "  2. SWEET ★ HONEY ★ BUCKIIN’ by Beyoncé\n",
      "     Track ID: 02159dd4-018a-4264-acca-19d2edc233d2\n",
      "     Similarity: 0.9955\n",
      "\n",
      "  3. The Lucky One by Taylor Swift\n",
      "     Track ID: dddaf5be-1342-438b-9f47-2dbc470cc7ee\n",
      "     Similarity: 0.9918\n",
      "\n",
      "  4. Mine by Taylor Swift\n",
      "     Track ID: 2fedfd5e-d88e-458c-9890-0265e8c41a8c\n",
      "     Similarity: 0.9906\n",
      "\n",
      "  5. White Ferrari by Frank Ocean\n",
      "     Track ID: a1f25623-f56c-4f36-bcce-67488d04e7cc\n",
      "     Similarity: 0.9894\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "QUERY TRACK: The Lucky One by Taylor Swift\n",
      "Track ID: dddaf5be-1342-438b-9f47-2dbc470cc7ee\n",
      "================================================================================\n",
      "\n",
      "📊 OPENL3 Recommendations (Top-5):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. Mine by Taylor Swift\n",
      "     Track ID: 2fedfd5e-d88e-458c-9890-0265e8c41a8c\n",
      "     Similarity: 0.9968\n",
      "\n",
      "  2. SWEET ★ HONEY ★ BUCKIIN’ by Beyoncé\n",
      "     Track ID: 02159dd4-018a-4264-acca-19d2edc233d2\n",
      "     Similarity: 0.9962\n",
      "\n",
      "  3. prfct by Sabrina Carpenter\n",
      "     Track ID: 1b85a6a7-0175-4bf1-ba75-9dc7f5505689\n",
      "     Similarity: 0.9952\n",
      "\n",
      "  4. I Should Have Known Better by The Beatles\n",
      "     Track ID: 045ccc99-34d4-4c23-90a9-1c16101e86bb\n",
      "     Similarity: 0.9947\n",
      "\n",
      "  5. White Ferrari by Frank Ocean\n",
      "     Track ID: a1f25623-f56c-4f36-bcce-67488d04e7cc\n",
      "     Similarity: 0.9942\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "QUERY TRACK: prfct by Sabrina Carpenter\n",
      "Track ID: 1b85a6a7-0175-4bf1-ba75-9dc7f5505689\n",
      "================================================================================\n",
      "\n",
      "📊 OPENL3 Recommendations (Top-5):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. SWEET ★ HONEY ★ BUCKIIN’ by Beyoncé\n",
      "     Track ID: 02159dd4-018a-4264-acca-19d2edc233d2\n",
      "     Similarity: 0.9976\n",
      "\n",
      "  2. fake smile by Ariana Grande\n",
      "     Track ID: 2e9ff3e6-9c69-4675-a249-abcf05241811\n",
      "     Similarity: 0.9967\n",
      "\n",
      "  3. The Lucky One by Taylor Swift\n",
      "     Track ID: dddaf5be-1342-438b-9f47-2dbc470cc7ee\n",
      "     Similarity: 0.9952\n",
      "\n",
      "  4. Mine by Taylor Swift\n",
      "     Track ID: 2fedfd5e-d88e-458c-9890-0265e8c41a8c\n",
      "     Similarity: 0.9943\n",
      "\n",
      "  5. White Ferrari by Frank Ocean\n",
      "     Track ID: a1f25623-f56c-4f36-bcce-67488d04e7cc\n",
      "     Similarity: 0.9902\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "QUERY TRACK: I Saw Her Standing There by The Beatles\n",
      "Track ID: 9a7c7ee2-6b9e-461d-bab0-c273c6997461\n",
      "================================================================================\n",
      "\n",
      "📊 OPENL3 Recommendations (Top-5):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. Mine by Taylor Swift\n",
      "     Track ID: 2fedfd5e-d88e-458c-9890-0265e8c41a8c\n",
      "     Similarity: 0.9949\n",
      "\n",
      "  2. I Should Have Known Better by The Beatles\n",
      "     Track ID: 045ccc99-34d4-4c23-90a9-1c16101e86bb\n",
      "     Similarity: 0.9938\n",
      "\n",
      "  3. The Lucky One by Taylor Swift\n",
      "     Track ID: dddaf5be-1342-438b-9f47-2dbc470cc7ee\n",
      "     Similarity: 0.9913\n",
      "\n",
      "  4. Within You Without You by The Beatles\n",
      "     Track ID: 7b01bee3-dd37-4221-8535-3792f5e9280e\n",
      "     Similarity: 0.9910\n",
      "\n",
      "  5. SWEET ★ HONEY ★ BUCKIIN’ by Beyoncé\n",
      "     Track ID: 02159dd4-018a-4264-acca-19d2edc233d2\n",
      "     Similarity: 0.9886\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "QUERY TRACK: White Ferrari by Frank Ocean\n",
      "Track ID: a1f25623-f56c-4f36-bcce-67488d04e7cc\n",
      "================================================================================\n",
      "\n",
      "📊 OPENL3 Recommendations (Top-5):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. The Lucky One by Taylor Swift\n",
      "     Track ID: dddaf5be-1342-438b-9f47-2dbc470cc7ee\n",
      "     Similarity: 0.9942\n",
      "\n",
      "  2. SWEET ★ HONEY ★ BUCKIIN’ by Beyoncé\n",
      "     Track ID: 02159dd4-018a-4264-acca-19d2edc233d2\n",
      "     Similarity: 0.9930\n",
      "\n",
      "  3. Mine by Taylor Swift\n",
      "     Track ID: 2fedfd5e-d88e-458c-9890-0265e8c41a8c\n",
      "     Similarity: 0.9927\n",
      "\n",
      "  4. I Should Have Known Better by The Beatles\n",
      "     Track ID: 045ccc99-34d4-4c23-90a9-1c16101e86bb\n",
      "     Similarity: 0.9925\n",
      "\n",
      "  5. Within You Without You by The Beatles\n",
      "     Track ID: 7b01bee3-dd37-4221-8535-3792f5e9280e\n",
      "     Similarity: 0.9922\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "QUERY TRACK: SWEET ★ HONEY ★ BUCKIIN’ by Beyoncé\n",
      "Track ID: 02159dd4-018a-4264-acca-19d2edc233d2\n",
      "================================================================================\n",
      "\n",
      "📊 OPENL3 Recommendations (Top-5):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. prfct by Sabrina Carpenter\n",
      "     Track ID: 1b85a6a7-0175-4bf1-ba75-9dc7f5505689\n",
      "     Similarity: 0.9976\n",
      "\n",
      "  2. The Lucky One by Taylor Swift\n",
      "     Track ID: dddaf5be-1342-438b-9f47-2dbc470cc7ee\n",
      "     Similarity: 0.9962\n",
      "\n",
      "  3. fake smile by Ariana Grande\n",
      "     Track ID: 2e9ff3e6-9c69-4675-a249-abcf05241811\n",
      "     Similarity: 0.9955\n",
      "\n",
      "  4. Mine by Taylor Swift\n",
      "     Track ID: 2fedfd5e-d88e-458c-9890-0265e8c41a8c\n",
      "     Similarity: 0.9951\n",
      "\n",
      "  5. White Ferrari by Frank Ocean\n",
      "     Track ID: a1f25623-f56c-4f36-bcce-67488d04e7cc\n",
      "     Similarity: 0.9930\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "QUERY TRACK: Just the Way You Are by Billy Joel\n",
      "Track ID: 242d99f7-5b74-44db-928e-94ccc14845a4\n",
      "================================================================================\n",
      "\n",
      "📊 OPENL3 Recommendations (Top-5):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. White Ferrari by Frank Ocean\n",
      "     Track ID: a1f25623-f56c-4f36-bcce-67488d04e7cc\n",
      "     Similarity: 0.9898\n",
      "\n",
      "  2. The Lucky One by Taylor Swift\n",
      "     Track ID: dddaf5be-1342-438b-9f47-2dbc470cc7ee\n",
      "     Similarity: 0.9874\n",
      "\n",
      "  3. fake smile by Ariana Grande\n",
      "     Track ID: 2e9ff3e6-9c69-4675-a249-abcf05241811\n",
      "     Similarity: 0.9872\n",
      "\n",
      "  4. Mine by Taylor Swift\n",
      "     Track ID: 2fedfd5e-d88e-458c-9890-0265e8c41a8c\n",
      "     Similarity: 0.9869\n",
      "\n",
      "  5. I Should Have Known Better by The Beatles\n",
      "     Track ID: 045ccc99-34d4-4c23-90a9-1c16101e86bb\n",
      "     Similarity: 0.9868\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "QUERY TRACK: I Should Have Known Better by The Beatles\n",
      "Track ID: 045ccc99-34d4-4c23-90a9-1c16101e86bb\n",
      "================================================================================\n",
      "\n",
      "📊 OPENL3 Recommendations (Top-5):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. Mine by Taylor Swift\n",
      "     Track ID: 2fedfd5e-d88e-458c-9890-0265e8c41a8c\n",
      "     Similarity: 0.9961\n",
      "\n",
      "  2. Within You Without You by The Beatles\n",
      "     Track ID: 7b01bee3-dd37-4221-8535-3792f5e9280e\n",
      "     Similarity: 0.9948\n",
      "\n",
      "  3. The Lucky One by Taylor Swift\n",
      "     Track ID: dddaf5be-1342-438b-9f47-2dbc470cc7ee\n",
      "     Similarity: 0.9947\n",
      "\n",
      "  4. I Saw Her Standing There by The Beatles\n",
      "     Track ID: 9a7c7ee2-6b9e-461d-bab0-c273c6997461\n",
      "     Similarity: 0.9938\n",
      "\n",
      "  5. White Ferrari by Frank Ocean\n",
      "     Track ID: a1f25623-f56c-4f36-bcce-67488d04e7cc\n",
      "     Similarity: 0.9925\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "QUERY TRACK: Mine by Taylor Swift\n",
      "Track ID: 2fedfd5e-d88e-458c-9890-0265e8c41a8c\n",
      "================================================================================\n",
      "\n",
      "📊 OPENL3 Recommendations (Top-5):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. The Lucky One by Taylor Swift\n",
      "     Track ID: dddaf5be-1342-438b-9f47-2dbc470cc7ee\n",
      "     Similarity: 0.9968\n",
      "\n",
      "  2. I Should Have Known Better by The Beatles\n",
      "     Track ID: 045ccc99-34d4-4c23-90a9-1c16101e86bb\n",
      "     Similarity: 0.9961\n",
      "\n",
      "  3. SWEET ★ HONEY ★ BUCKIIN’ by Beyoncé\n",
      "     Track ID: 02159dd4-018a-4264-acca-19d2edc233d2\n",
      "     Similarity: 0.9951\n",
      "\n",
      "  4. I Saw Her Standing There by The Beatles\n",
      "     Track ID: 9a7c7ee2-6b9e-461d-bab0-c273c6997461\n",
      "     Similarity: 0.9949\n",
      "\n",
      "  5. prfct by Sabrina Carpenter\n",
      "     Track ID: 1b85a6a7-0175-4bf1-ba75-9dc7f5505689\n",
      "     Similarity: 0.9943\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "================================================================================\n",
      "QUERY TRACK: Within You Without You by The Beatles\n",
      "Track ID: 7b01bee3-dd37-4221-8535-3792f5e9280e\n",
      "================================================================================\n",
      "\n",
      "📊 OPENL3 Recommendations (Top-5):\n",
      "--------------------------------------------------------------------------------\n",
      "  1. I Should Have Known Better by The Beatles\n",
      "     Track ID: 045ccc99-34d4-4c23-90a9-1c16101e86bb\n",
      "     Similarity: 0.9948\n",
      "\n",
      "  2. Mine by Taylor Swift\n",
      "     Track ID: 2fedfd5e-d88e-458c-9890-0265e8c41a8c\n",
      "     Similarity: 0.9940\n",
      "\n",
      "  3. The Lucky One by Taylor Swift\n",
      "     Track ID: dddaf5be-1342-438b-9f47-2dbc470cc7ee\n",
      "     Similarity: 0.9922\n",
      "\n",
      "  4. White Ferrari by Frank Ocean\n",
      "     Track ID: a1f25623-f56c-4f36-bcce-67488d04e7cc\n",
      "     Similarity: 0.9922\n",
      "\n",
      "  5. I Saw Her Standing There by The Beatles\n",
      "     Track ID: 9a7c7ee2-6b9e-461d-bab0-c273c6997461\n",
      "     Similarity: 0.9910\n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Generate recommendations for all sampled tracks\n",
    "print(\"Generating recommendations for all sampled tracks...\\n\")\n",
    "\n",
    "rec_engines = {\n",
    "    \"OpenL3\": rec_engine_openl3\n",
    "    # \"PANNs\": rec_engine_panns\n",
    "}\n",
    "\n",
    "for musicbrainz_id in df_sample['musicbrainz_id']:\n",
    "    display_recommendations(musicbrainz_id, df_sample, rec_engines, top_k=5)\n",
    "    print(\"-----\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "091c3275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>musicbrainz_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>album</th>\n",
       "      <th>album_id</th>\n",
       "      <th>release_date</th>\n",
       "      <th>country</th>\n",
       "      <th>length</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2e9ff3e6-9c69-4675-a249-abcf05241811</td>\n",
       "      <td>fake smile</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>f4fdbb4c-e4b7-47a0-b83b-d91bbfcfa387</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>f3c1f76d-d436-4402-8888-1fdcf9e6cba8</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>US</td>\n",
       "      <td>208000.0</td>\n",
       "      <td>rec\\2e9ff3e6-9c69-4675-a249-abcf05241811.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dddaf5be-1342-438b-9f47-2dbc470cc7ee</td>\n",
       "      <td>The Lucky One</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>20244d07-534f-4eff-b4d4-930878889970</td>\n",
       "      <td>The Red Tour Live</td>\n",
       "      <td>8963a851-256d-4645-8bc7-245f6e3990ed</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235000.0</td>\n",
       "      <td>rec\\dddaf5be-1342-438b-9f47-2dbc470cc7ee.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1b85a6a7-0175-4bf1-ba75-9dc7f5505689</td>\n",
       "      <td>prfct</td>\n",
       "      <td>Sabrina Carpenter</td>\n",
       "      <td>1882fe91-cdd9-49c9-9956-8e06a3810bd4</td>\n",
       "      <td>Singular: Act I</td>\n",
       "      <td>2600e60d-cf59-4af3-9d60-dcbdd7f78a50</td>\n",
       "      <td>2018-11-09</td>\n",
       "      <td>XW</td>\n",
       "      <td>166000.0</td>\n",
       "      <td>rec\\1b85a6a7-0175-4bf1-ba75-9dc7f5505689.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9a7c7ee2-6b9e-461d-bab0-c273c6997461</td>\n",
       "      <td>I Saw Her Standing There</td>\n",
       "      <td>The Beatles</td>\n",
       "      <td>b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d</td>\n",
       "      <td>Chronology, Volume 4: Yesterday (1965-1966)</td>\n",
       "      <td>3f60adc0-f72b-44d5-8367-02a9167355b5</td>\n",
       "      <td>1994-01-01</td>\n",
       "      <td>AU</td>\n",
       "      <td>220840.0</td>\n",
       "      <td>rec\\9a7c7ee2-6b9e-461d-bab0-c273c6997461.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1f25623-f56c-4f36-bcce-67488d04e7cc</td>\n",
       "      <td>White Ferrari</td>\n",
       "      <td>Frank Ocean</td>\n",
       "      <td>e520459c-dff4-491d-a6e4-c97be35e0044</td>\n",
       "      <td>Blonde</td>\n",
       "      <td>8294645a-f996-44b6-9060-7f189b9f59f3</td>\n",
       "      <td>2016-08-20</td>\n",
       "      <td>XW</td>\n",
       "      <td>249000.0</td>\n",
       "      <td>rec\\a1f25623-f56c-4f36-bcce-67488d04e7cc.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>02159dd4-018a-4264-acca-19d2edc233d2</td>\n",
       "      <td>SWEET ★ HONEY ★ BUCKIIN’</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>859d0860-d480-4efd-970c-c05d5f1776b8</td>\n",
       "      <td>Cowboy Carter</td>\n",
       "      <td>2a2aa1bb-c082-450b-8a91-20256f485114</td>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>US</td>\n",
       "      <td>296186.0</td>\n",
       "      <td>rec\\02159dd4-018a-4264-acca-19d2edc233d2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>242d99f7-5b74-44db-928e-94ccc14845a4</td>\n",
       "      <td>Just the Way You Are</td>\n",
       "      <td>Billy Joel</td>\n",
       "      <td>64b94289-9474-4d43-8c93-918ccc1920d1</td>\n",
       "      <td>Live on Air</td>\n",
       "      <td>9e2c1c43-6fef-43e7-b7e5-081d4545ebc7</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>IT</td>\n",
       "      <td>249000.0</td>\n",
       "      <td>rec\\242d99f7-5b74-44db-928e-94ccc14845a4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>045ccc99-34d4-4c23-90a9-1c16101e86bb</td>\n",
       "      <td>I Should Have Known Better</td>\n",
       "      <td>The Beatles</td>\n",
       "      <td>b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d</td>\n",
       "      <td>Perfect Collection, Volume 3: 1963–1964</td>\n",
       "      <td>573840c2-f041-4ad4-9b6c-58264eb973b7</td>\n",
       "      <td>1987-01-01</td>\n",
       "      <td>JP</td>\n",
       "      <td>165466.0</td>\n",
       "      <td>rec\\045ccc99-34d4-4c23-90a9-1c16101e86bb.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2fedfd5e-d88e-458c-9890-0265e8c41a8c</td>\n",
       "      <td>Mine</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>20244d07-534f-4eff-b4d4-930878889970</td>\n",
       "      <td>Taylor Swift Karaoke: Speak Now</td>\n",
       "      <td>6cdd62a6-db01-4902-9481-d6e27ce756d9</td>\n",
       "      <td>2010-12-20</td>\n",
       "      <td>US</td>\n",
       "      <td>241106.0</td>\n",
       "      <td>rec\\2fedfd5e-d88e-458c-9890-0265e8c41a8c.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7b01bee3-dd37-4221-8535-3792f5e9280e</td>\n",
       "      <td>Within You Without You</td>\n",
       "      <td>The Beatles</td>\n",
       "      <td>b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d</td>\n",
       "      <td>Sgt. Pepper Naked</td>\n",
       "      <td>e5f85542-4987-4c41-8b8d-36daf0a3d118</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>304715.0</td>\n",
       "      <td>rec\\7b01bee3-dd37-4221-8535-3792f5e9280e.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         musicbrainz_id                       title  \\\n",
       "0  2e9ff3e6-9c69-4675-a249-abcf05241811                  fake smile   \n",
       "1  dddaf5be-1342-438b-9f47-2dbc470cc7ee               The Lucky One   \n",
       "2  1b85a6a7-0175-4bf1-ba75-9dc7f5505689                       prfct   \n",
       "3  9a7c7ee2-6b9e-461d-bab0-c273c6997461    I Saw Her Standing There   \n",
       "4  a1f25623-f56c-4f36-bcce-67488d04e7cc               White Ferrari   \n",
       "5  02159dd4-018a-4264-acca-19d2edc233d2    SWEET ★ HONEY ★ BUCKIIN’   \n",
       "6  242d99f7-5b74-44db-928e-94ccc14845a4        Just the Way You Are   \n",
       "7  045ccc99-34d4-4c23-90a9-1c16101e86bb  I Should Have Known Better   \n",
       "8  2fedfd5e-d88e-458c-9890-0265e8c41a8c                        Mine   \n",
       "9  7b01bee3-dd37-4221-8535-3792f5e9280e      Within You Without You   \n",
       "\n",
       "              artist                             artist_id  \\\n",
       "0      Ariana Grande  f4fdbb4c-e4b7-47a0-b83b-d91bbfcfa387   \n",
       "1       Taylor Swift  20244d07-534f-4eff-b4d4-930878889970   \n",
       "2  Sabrina Carpenter  1882fe91-cdd9-49c9-9956-8e06a3810bd4   \n",
       "3        The Beatles  b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d   \n",
       "4        Frank Ocean  e520459c-dff4-491d-a6e4-c97be35e0044   \n",
       "5            Beyoncé  859d0860-d480-4efd-970c-c05d5f1776b8   \n",
       "6         Billy Joel  64b94289-9474-4d43-8c93-918ccc1920d1   \n",
       "7        The Beatles  b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d   \n",
       "8       Taylor Swift  20244d07-534f-4eff-b4d4-930878889970   \n",
       "9        The Beatles  b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d   \n",
       "\n",
       "                                         album  \\\n",
       "0                                thank u, next   \n",
       "1                            The Red Tour Live   \n",
       "2                              Singular: Act I   \n",
       "3  Chronology, Volume 4: Yesterday (1965-1966)   \n",
       "4                                       Blonde   \n",
       "5                                Cowboy Carter   \n",
       "6                                  Live on Air   \n",
       "7      Perfect Collection, Volume 3: 1963–1964   \n",
       "8              Taylor Swift Karaoke: Speak Now   \n",
       "9                            Sgt. Pepper Naked   \n",
       "\n",
       "                               album_id release_date country    length  \\\n",
       "0  f3c1f76d-d436-4402-8888-1fdcf9e6cba8   2019-02-07      US  208000.0   \n",
       "1  8963a851-256d-4645-8bc7-245f6e3990ed   2014-01-01     NaN  235000.0   \n",
       "2  2600e60d-cf59-4af3-9d60-dcbdd7f78a50   2018-11-09      XW  166000.0   \n",
       "3  3f60adc0-f72b-44d5-8367-02a9167355b5   1994-01-01      AU  220840.0   \n",
       "4  8294645a-f996-44b6-9060-7f189b9f59f3   2016-08-20      XW  249000.0   \n",
       "5  2a2aa1bb-c082-450b-8a91-20256f485114   2024-03-29      US  296186.0   \n",
       "6  9e2c1c43-6fef-43e7-b7e5-081d4545ebc7   2011-03-14      IT  249000.0   \n",
       "7  573840c2-f041-4ad4-9b6c-58264eb973b7   1987-01-01      JP  165466.0   \n",
       "8  6cdd62a6-db01-4902-9481-d6e27ce756d9   2010-12-20      US  241106.0   \n",
       "9  e5f85542-4987-4c41-8b8d-36daf0a3d118   2005-01-01      US  304715.0   \n",
       "\n",
       "                                      file_path  \n",
       "0  rec\\2e9ff3e6-9c69-4675-a249-abcf05241811.wav  \n",
       "1  rec\\dddaf5be-1342-438b-9f47-2dbc470cc7ee.wav  \n",
       "2  rec\\1b85a6a7-0175-4bf1-ba75-9dc7f5505689.wav  \n",
       "3  rec\\9a7c7ee2-6b9e-461d-bab0-c273c6997461.wav  \n",
       "4  rec\\a1f25623-f56c-4f36-bcce-67488d04e7cc.wav  \n",
       "5  rec\\02159dd4-018a-4264-acca-19d2edc233d2.wav  \n",
       "6  rec\\242d99f7-5b74-44db-928e-94ccc14845a4.wav  \n",
       "7  rec\\045ccc99-34d4-4c23-90a9-1c16101e86bb.wav  \n",
       "8  rec\\2fedfd5e-d88e-458c-9890-0265e8c41a8c.wav  \n",
       "9  rec\\7b01bee3-dd37-4221-8535-3792f5e9280e.wav  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbfb53c",
   "metadata": {},
   "source": [
    "#### 5.4 Summary Statistics\n",
    "\n",
    "Analyze recommendation patterns across models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6bbc55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Recommendation Statistics:\n",
      "============================================================\n",
      "Total recommendations generated: 50\n",
      "\n",
      "Average similarity scores by model:\n",
      "            mean       std       min       max\n",
      "model                                         \n",
      "OpenL3  0.994416  0.002827  0.985572  0.997532\n",
      "\n",
      "Recommendations per model:\n",
      "model\n",
      "OpenL3    50\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Collect all recommendations for analysis\n",
    "all_recommendations = []\n",
    "\n",
    "for musicbrainz_id in df_sample['musicbrainz_id']:\n",
    "    for model_name, rec_engine in rec_engines.items():\n",
    "        try:\n",
    "            recs = rec_engine.get_recommendations(musicbrainz_id, top_k=5)\n",
    "            recs['query_musicbrainz_id'] = musicbrainz_id\n",
    "            recs['model'] = model_name\n",
    "            all_recommendations.append(recs)\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting recommendations for {musicbrainz_id} with {model_name}: {e}\")\n",
    "\n",
    "if all_recommendations:\n",
    "    df_all_recs = pd.concat(all_recommendations, ignore_index=True)\n",
    "    \n",
    "    print(\"📈 Recommendation Statistics:\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total recommendations generated: {len(df_all_recs)}\")\n",
    "    print(f\"\\nAverage similarity scores by model:\")\n",
    "    print(df_all_recs.groupby('model')['similarity_score'].agg(['mean', 'std', 'min', 'max']))\n",
    "    \n",
    "    print(f\"\\nRecommendations per model:\")\n",
    "    print(df_all_recs['model'].value_counts())\n",
    "    \n",
    "    # Check genre consistency (if genre column exists)\n",
    "    if 'genre' in df_all_recs.columns:\n",
    "        print(f\"\\nGenre diversity in recommendations:\")\n",
    "        genre_counts = df_all_recs.groupby('model')['genre'].nunique()\n",
    "        print(genre_counts)\n",
    "else:\n",
    "    print(\"⚠️  No recommendations generated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ca611",
   "metadata": {},
   "source": [
    "\n",
    "### SECTION 6 — COMPARISON & INSIGHTS\n",
    "\n",
    "\n",
    "Analysis and comparison of the three embedding models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fab9ad",
   "metadata": {},
   "source": [
    "## 6.1 Model Characteristics\n",
    "\n",
    "### OpenL3\n",
    "- **Embedding Dimension**: 512D\n",
    "- **Training**: Trained on audio-visual data (AudioSet + video)\n",
    "- **Strengths**: \n",
    "  - Good at capturing general audio content\n",
    "  - Works well for music classification\n",
    "  - Fast inference\n",
    "- **Use Cases**: \n",
    "  - General music similarity\n",
    "  - Content-based filtering\n",
    "  - Quick prototyping\n",
    "\n",
    "### PANNs\n",
    "- **Embedding Dimension**: 2048D\n",
    "- **Training**: Large-scale pretraining on AudioSet (20K classes)\n",
    "- **Strengths**:\n",
    "  - Rich feature representation (higher dimensionality)\n",
    "  - Excellent for fine-grained audio analysis\n",
    "  - State-of-the-art on many audio tasks\n",
    "- **Use Cases**:\n",
    "  - Detailed audio similarity\n",
    "  - When you need the most expressive features\n",
    "  - Production systems with computational resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb9879",
   "metadata": {},
   "source": [
    "## 6.2 Which Embedding Method Captures Timbre Better?\n",
    "\n",
    "**Timbre** refers to the quality or \"color\" of sound that distinguishes different instruments or voices playing the same note.\n",
    "\n",
    "### Analysis:\n",
    "\n",
    "1. **PANNs** likely captures timbre best:\n",
    "   - Highest dimensionality (2048D) allows for more nuanced feature representation\n",
    "   - Trained on AudioSet with many instrument classes\n",
    "   - Deep CNN architecture captures spectral-temporal patterns well\n",
    "\n",
    "2. **OpenL3** provides general timbre features:\n",
    "   - Good baseline for timbre similarity\n",
    "   - May miss fine-grained distinctions\n",
    "   - Faster but less detailed\n",
    "\n",
    "### Recommendation:\n",
    "For **timbre-focused** applications, use **PANNs** for the richest representation, .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a534e",
   "metadata": {},
   "source": [
    "## 6.3 Which Retrieves More Genre-Similar Songs?\n",
    "\n",
    "**Genre similarity** refers to how well recommendations match the genre of the query track.\n",
    "\n",
    "### Analysis:\n",
    "\n",
    "1. **OpenL3** provides decent genre clustering:\n",
    "   - Trained on AudioSet which has genre labels\n",
    "   - Good at high-level music categorization\n",
    "   - May group similar genres together\n",
    "\n",
    "2. **PANNs** captures detailed features:\n",
    "   - May focus on acoustic features rather than genre boundaries\n",
    "   - Could retrieve songs with similar instrumentation but different genres\n",
    "   - More fine-grained, potentially less genre-focused\n",
    "\n",
    "### Recommendation:\n",
    "For **genre-based** recommendations, use **OpenL3**.  in your metadata, while OpenL3 provides a good balance of speed and genre awareness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa211a3",
   "metadata": {},
   "source": [
    "## 6.4 Where Each Model May Be Used in the Final Recommendation Engine\n",
    "\n",
    "### Hybrid Recommendation Strategy:\n",
    "\n",
    "#### **Tier 1: Fast Filtering (OpenL3)**\n",
    "- Use for initial candidate generation from large catalogs\n",
    "- Quick similarity search to reduce search space\n",
    "- Good for real-time recommendations\n",
    "- **When to use**: \n",
    "  - Cold start scenarios\n",
    "  - Large-scale filtering (millions of tracks)\n",
    "  - Real-time recommendation APIs\n",
    "\n",
    "#### **Tier 2: Fine-Grained Matching (PANNs)**\n",
    "- Use for final ranking and detailed similarity\n",
    "- Best for precision when you need exact matches\n",
    "- Highest quality but slower\n",
    "- **When to use**:\n",
    "  - Final ranking stage\n",
    "  - When computational resources allow\n",
    "  - Precision-critical applications\n",
    "  - Detailed audio analysis\n",
    "\n",
    "### Recommended Pipeline:\n",
    "\n",
    "```\n",
    "1. User Query → OpenL3 → Get top 1000 candidates (fast)\n",
    "2. Filter by metadata/genre → Reduce to top 100\n",
    "4. PANNs fine-grained → Final top 10 recommendations\n",
    "```\n",
    "\n",
    "### Alternative: Ensemble Approach\n",
    "- Combine embeddings from both models\n",
    "- Weighted average or concatenation\n",
    "- Train a meta-model to learn optimal combination\n",
    "- **Best for**: Production systems with sufficient resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b07dc",
   "metadata": {},
   "source": [
    "## 6.5 Practical Considerations\n",
    "\n",
    "### Computational Requirements:\n",
    "- **OpenL3**: Fastest, lowest memory (~512D embeddings)\n",
    "- **PANNs**: Slowest, highest memory (~2048D embeddings)\n",
    "\n",
    "### Storage:\n",
    "- **OpenL3**: ~2KB per track (512 floats)\n",
    "- **PANNs**: ~8KB per track (2048 floats)\n",
    "\n",
    "### Accuracy vs Speed Trade-off:\n",
    "- **Speed priority**: Use OpenL3\n",
    "- **Accuracy priority**: Use PANNs\n",
    "\n",
    "### Final Recommendation:\n",
    "For a **production recommendation engine**, consider:\n",
    "1. **Start with OpenL3** for scalability\n",
    "2. **Use PANNs** for premium/precision features\n",
    "3. **Implement caching** for frequently accessed tracks\n",
    "4. **Use FAISS** for efficient similarity search at scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd0899",
   "metadata": {},
   "source": [
    "\n",
    "# SUMMARY\n",
    "\n",
    "\n",
    "This notebook provides a complete implementation of:\n",
    "\n",
    "✅ **Two audio embedding models** (OpenL3, PANNs) using a factory pattern  \n",
    "✅ **Embedding extraction** for audio files  \n",
    "✅ **FAISS-based recommendation engine** for fast similarity search  \n",
    "✅ **Parquet storage** for efficient embedding persistence  \n",
    "✅ **Comprehensive comparison** and usage recommendations  \n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **OpenL3**: Best for fast, general-purpose music similarity\n",
    "2. **PANNs**: Best for detailed, fine-grained audio analysis\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Scale to larger datasets\n",
    "- Implement ensemble methods\n",
    "- Add evaluation metrics (precision@k, recall@k)\n",
    "- Deploy as a production API\n",
    "- Fine-tune models on your specific music catalog\n",
    "\n",
    "### Files Generated:\n",
    "\n",
    "- `openl3_embeddings.parquet`: OpenL3 embeddings\n",
    "- `panns_embeddings.parquet`: PANNs embeddings\n",
    "\n",
    "All embeddings are stored with track metadata for easy retrieval and analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3581c493",
   "metadata": {},
   "source": [
    "\n",
    "# SECTION 5 — SONG RECOMMENDATIONS\n",
    "\n",
    "\n",
    "Build a recommendation system using the generated embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc03f02a",
   "metadata": {},
   "source": [
    "## 5.1 Recommendation System Class\n",
    "\n",
    "Create a recommendation system using FAISS for fast similarity search.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
